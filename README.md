# Vektor

## Project Overview

Vektor is a personal project that serves as my playground for delving into the
intricacies of Natural Language Processing (NLP) and Transformer models. As a
self-initiated educational endeavor, it's primarily focused on deepening my
understanding of these complex topics from the ground up.

## Current Focus

The project initially began as an exploration into encoding, decoding, and
tokenization. However, it has since evolved into a more comprehensive study,
particularly focusing on implementing the skip gram model and understanding
Transformer architecture. This evolution stems from my realization that
mastering these concepts in Python, a language I'm more comfortable with, is
more feasible than tackling them in C/C++ as initially attempted.

## Personal Learning Journey

Vektor is not just about the final output but more about the journey and the
learning process. The project is a testament to the iterative nature of
learning, especially in the complex domain of NLP and machine learning. It's a
reflection of my hands-on approach to understanding and building these systems
from scratch, using only essential libraries and tools to reinforce fundamental
learning.

## Status and Goals

As of now, Vektor remains a work-in-progress, a testament to the ongoing journey
of learning and discovery in the field of NLP and AI. The main goals include:

- Gaining a deeper understanding of Transformer models and their related
  components.
- Experimenting with different aspects of NLP, including tokenization and
  encoding, memory, cognitive architecture, and more.
- Keeping the project open for new directions and learnings as they arise.

## Documentation

For a deeper dive into the Vektor project, the documentation provides
comprehensive insights and details:

- **Project Overview**: For a detailed look at the overall design, architecture,
  and goals of the Vektor project, see
  [Project Overview](docs/VektorProjectOverview.md).

- **Technical Documentation**: Explore various technical aspects, including
  tokenization, encoding, and model implementation, in the dedicated
  [technical documents](docs/). This includes:

  - [Tokenization and Encoding](docs/tokenization/)
  - [Model Architecture](docs/model/)

- **Upcoming Documentation**: I'm continually working on expanding the
  documentation to cover more aspects of the project. Keep an eye on the `docs/`
  directory for the latest updates.

The documentation is a living entity and is regularly updated to reflect the
latest progress and insights into the Vektor project.

## Contributions and Collaborations

While Vektor is a personal project, input, suggestions, and discussions are
always welcome. They can provide fresh perspectives and insights, which are
invaluable in a learning journey like this.
